[
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "assignment/index.html#weekly-check-in",
    "href": "assignment/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in thsi course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "assignment/index.html#evaluation-assignments",
    "href": "assignment/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "assignment/index.html#exams",
    "href": "assignment/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Práctica 1. Introducción al lenguaje R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos a las herramientas que permiten establecer un flujo de trabajo en R.\nEn detalle, aprenderemos:\n\nCómo establecer un flujo de trabajo mediante scripts y Rprojects siguiendo el protocolo IPO\nCómo crear un proyecto de R (R.proyect)\nCómo crear un script (hoja) en R\n\n\n\n\nEn presentación. Prontamente síntesis aquí."
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en los procedimientos básicos del uso del lenguaje y ambiente R.\nEn detalle, aprenderemos:\n\nHerramientas básicas de programación en R\nOperadores en R\nTipos de datos\n\n\n\n\nRevisemos algunos conocimientos básicos para la programación en R. Pero antes, tengamos dos cosas en mente:\n\nPrimero, ¿qué es codificar?, en programación codificar corresponde a un proceso de entrega de instrucciones en un lenguaje específico, siguiendo un orden lógico y coherente.\nSegundo, de aquí en adelante nos manejaremos con una máxima en el curso; existe un acuerdo implícito entre tú y R: R hará todos los cálculos por ti, pero en cambio tú debes dar las instrucciones con total precisión.\n\n\n\nUno de los usos más sencillos y que están a la base de R, es usarlo como una calculadora.\n\n5+5\n\n[1] 10\n\n25/5\n\n[1] 5\n\n2*2\n\n[1] 4\n\n27-2\n\n[1] 25\n\n\nComo podrás ver, el resultado de estas instrucciones aparecen como un [1] en la consola. También podemos hacer operatorias más complejas y con más cálculos.\n\n12*(7+2)+(45-32)+8\n\n[1] 129\n\n22^2 - 2^2\n\n[1] 480\n\n1/200 * 30\n\n[1] 0.15\n\n\n\n\n\nR es un lenguaje de programación orientado a objetos. ¿Qué significa eso?, implica que podemos crear elementos dentro del ambiente de R, a los cuales les asignaremos información que quedará almacenada, información que puede ir desde números, palabras, cálculos hasta grandes bases de datos.\nTodas las instrucciones en R en las que crees objetos, es decir, instrucciones de asignación, tendrán la misma estructura:\nnombre_objeto <- valor\nEl asignador <- se utiliza para crear objetos y forma parte de uno de los operadores usados en R.\nLos elementos que podemos asignar a objetos son múltiples, como números, palabras acompañadas siempre de corchetes \" \" y vectores que corresponden a un conjunto o secuencia de elementos del mismo tipo definidos por la funcion de concatenar = c().\nVeamos un ejemplo creando objetos:\n\nx <- 4 # asignar\n\nx # ejecutar\n\n[1] 4\n\ny <- \"Hola mundo\" # los carácteres alfabéticos siempre van acompañados de corchetes\n\ny \n\n[1] \"Hola mundo\"\n\n\n¿Y concatenando? Hacemos un vector.\n\nedad <- c(18,22,36,19,35) # concatenar (variable de razon)\n\nedad\n\n[1] 18 22 36 19 35\n\ngenero <- c(3,1,1,2,3) # masculino = 1; femenino = 2; transgenero = 3 (variable nominal)\n\ngenero \n\n[1] 3 1 1 2 3\n\ngse <- c(\"ABC1\", \"C2\", \"E\", \"AbC1\", \"E\")  # tambíen se pueden usar carácteres (variable ordinal)\n\ngse\n\n[1] \"ABC1\" \"C2\"   \"E\"    \"AbC1\" \"E\"   \n\n\n¡Hagamos una pequeño reto!: ¿Cuál es el valor de a y b? Si a <- 5; b <- a; a <- 4\n\na <- 5\nb <- a\na <- 4\n\nprint(a) # imprimir en la consola\n\n[1] 4\n\nprint(b)\n\n[1] 5\n\na + 10\n\n[1] 14\n\n\nAhora, sea z = a^2 ¿qué resultado obtenemos de a * b + z?\n\nz <- a^2 # asignar\n\na * b + z\n\n[1] 36\n\n\nAdemás de lo anterior, en R es fundamental la creación de data.frames. Un Data.frame es una estructura de datos de dos dimensiones (columnas y filas), donde las columnas pueden ser de diferente naturaleza, pero deben tener el mismo largo. A partir de ella agrupamos variables en una matriz, o sea, construimos una base de datos. Es como “pegar” las columnas (variables) una al lado de otra.\nCreemos un data.frame con los vectores que ya creamos antes.\n\nbase1 <- data.frame(genero, gse, edad) # Resulta como objeto de \"datos\" en\n                                       # entorno.\n\nbase1\n\n  genero  gse edad\n1      3 ABC1   18\n2      1   C2   22\n3      1    E   36\n4      2 AbC1   19\n5      3    E   35\n\n\nComo puedes ver, para crear el data.frame usamos la función que lleva el mismo nombre, colocando dentro del paréntesis los vectores que creamos anteriormente: data.frame(mis_vectores).\nAhora, creemos un data.frame desce cero. En este ejemplo, crearemos los vectores dentro de la función data.frame().\n\n# Ejemplo de como crear un data.frame desde 0: \n\nbase2 <- data.frame(Sexo=c(\"H\",\"M\",\"H\",\"M\",\"H\",\"M\"),\n                    Estatura=c(1.83,1.76,1.82,1.60,1.90,1.66),\n                    Peso=c(67,58,66,48,75,55))\n\nhead(base2)  # Me permite visualizar las primeras filas\n\n  Sexo Estatura Peso\n1    H     1.83   67\n2    M     1.76   58\n3    H     1.82   66\n4    M     1.60   48\n5    H     1.90   75\n6    M     1.66   55\n\n\n\n\n\n\nAntes de trabajar con datos, debemos conocer el concepto de operadores. Estos símbolos no son de uso exclusivo en R, pero no todos tienen el mismo significado que en otros softwares.\nLos operadores son símbolos que permiten, en los distintos procedimientos de procesamiento, simplificar procesos. Por ejemplo, serán útilizados cuando filtremos nuestros datos para personas de ciertas categorías, cuando calculemos variables nuevas (de manera aritmética o condicional) o, simplemente, cuando queramos hacer procesos “concatenados”.\n\n¡Veamos algunos ejemplos!\n\n20 == 5 # igualdad\n\n[1] FALSE\n\n30 >= 14 # mayor o igual que\n\n[1] TRUE\n\n22 <= 2 # menor o igual que\n\n[1] FALSE\n\n25 != 10 # no es igual a\n\n[1] TRUE\n\np = 10; y = 5; p <= y # operatoria en objetos\n\n[1] FALSE\n\n\n\n\n\n\n\nEn R, al igual que en la mayoría de lenguajes de programación, contamos con datos de diversos tipos, en razón de los cuales podemos realizar determinados procedimientos de tratamiento o análisis.\nLos tipos de datos están íntimamente relacionados con el nivel de medición de las variables a las que corresponden. Como viste en clases, la teoría de los niveles de medición contempla cuatro tipos:\n\n\n\n\nPara responder esta pregunta, ¡metamos nuestras manos en los datos!. En esta oportunidad trabajaremos sobre un subset de datos del Modulo de Desigualdad Social de la encuesta International Social Survey Programme del 2019. Esta base la descargaremos directamente desde internet por esta vez (en futuras sesiones aprenderemos cómo cargar bases de datos).\n\n#cargamos la base de datos desde internet\n\nload(url(\"https://github.com/Andreas-Lafferte/descriptiva/blob/main/data/db-proc.RData?raw=true\"))\n\nhead(rand_df) # ver primeros casos de la base\n\n       pais edad   sexo          ideologia percepcion_conflictos\n1     Suiza   23 Hombre          Izquierda                     2\n2     Chile   27  Mujer Sin identificación                     2\n3     Rusia   43  Mujer Sin identificación                     1\n4 Finlandia   71  Mujer Sin identificación                     1\n5     Japon   54  Mujer          Izquierda                     2\n6  Lituania   67  Mujer Sin identificación                     1\n\n\n\n\nLos datos character están directamente asociados a las variables cualitativas (o categóricas). Generalmente suelen ser variables de texto abierto, como es el caso de la variable pais, que detalla el país de procedencia de la persona encuestada.\nPara conocer cuál es el tipo de variable en R, utilizamos el comando class(), y para detallar dentro de la base de datos cuál es la variable de interés, utilizamos el símbolo $ posterior a la base de datos:\n\nclass(rand_df$pais) # siempre es la misma estructura = base$variable\n\n[1] \"character\"\n\n\nSin embargo, estas variables no tienden a ser las mejores a la hora de presentar nuestros resultados. Como solución, tenemos las variables de tipo Factor.\n\n\n\nLas variables de tipo factor son ideales para trabajar con variables de tipo nominal u ordinal. Esto es así debido a que permiten establecer un orden entre las categorías de la variable, lo cual es fundamental si trabajamos, por ejemplo, con variables nominales como el sexo de los encuestados, o si trabajamos con variables ordinales como su ideología política.\n\nclass(rand_df$sexo)\n\n[1] \"factor\"\n\nclass(rand_df$ideologia)\n\n[1] \"factor\"\n\n\n\n\n\nLas variables de tipo numeric son variables de tipo númerica, las cuales pueden ser intervales o de razón. Así, por ejemplo, cuando trabajamos con variables de razón trabajamos con variables como el número de hijos o la edad (aunque sería extraño encuestar a alguien con 0 años).\n\nclass(rand_df$edad)\n\n[1] \"numeric\""
  },
  {
    "objectID": "content/02-content.html#video-de-clase",
    "href": "content/02-content.html#video-de-clase",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "Video de clase",
    "text": "Video de clase"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\nEn detalle, aprenderemos:\n\nEstablecer un flujo de trabajo ordenado en un script (.R).\nInstalar y cargar paquetes y librerías, así como también leer bases de datos en R.\nLimpiar, transformar y exportar bases de datos en R.\n\n¡Al final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos!\n\n\n\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación: corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias a los datos para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis estadísticos, en este caso descriptivos, asociados a las preguntas e hipótesis de investigación.\n\nLos procesos de preparación y análisis vinculados tanto a datos y resultados se presentan en el siguiente esquema:\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código respectivo.\nEn esta guía nos centraremos en la preparación de datos con R. El documento de código de preparación tiene, por lo menos, 4 partes más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: instalar/cargar librerías a utilizar\nDatos: carga de datos\nProcesamiento: limpiar y transformar datos\nGuardar y exportar: generación de base de datos preparada para el análisis\n\nEn la práctica, tu script debería (ojalá siempre) verse así:\n\nEn el ejemplo vamos a procesar variables utilizando los datos de la encuesta ELSOC."
  },
  {
    "objectID": "content/03-content.html#cargar-librerías",
    "href": "content/03-content.html#cargar-librerías",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "1 Cargar librerías",
    "text": "1 Cargar librerías\nEn R se trabaja a partir de paquetes (packages) o librerías. ¿Qué son? de forma resumida, los paquetes son un conjunto de funciones o herramientas que puedens er usadas en R. La lógica es instalar paquetes y luego cargarlas (o llamarlas) cada vez que es necesario usarlas.\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\n\ninstall.packages(\"paquete\")\nlibrary(paquete)\n\nPero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\n\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\nLuego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes.\nEn este práctico utilizaremos seis paquetes\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\nsjmisc: explorar datos\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables\n\n\npacman::p_load(tidyverse,\n               sjmisc,\n               dplyr,\n               haven,\n               car)"
  },
  {
    "objectID": "content/03-content.html#importar-datos",
    "href": "content/03-content.html#importar-datos",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "2 Importar datos",
    "text": "2 Importar datos\nEn R es es posible importar y exportar fácilmente datos que se encuentren en cualquier formato: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Sin embargo, para poder hacerlo lo primero es instalar y cargar las librerías que contienen las funciones necesarias para la importación de distintos tipos de archivos.\nPero, ¿dónde están mis datos? Como hemos mencionado, nuestros datos los dejaremos en la carpeta input/data de nuestro proyecto. La base con la que trabajaremos en este práctico pueden encontrarla en el material docente en U-Cursos, o bien, en n el siguiente enlace podrán descargar el archivo .zip que contiene la base ELSOC 2021.\nLuego de descargar y descomprimir los datos, asegurate de dejar el archivo .sav en la carpeta de tu proyecto input/data. Nota: Los datos tendrán distinto nombre según su formato (.sav, .csv, .dta, etc.).\nUna vez descargados los datos y cargado el paquete haven, procedemos a importar nuestra base de datos. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con read_sav(), crearemos un objeto llamado elsoc_2021. Fijate en el Enviroment, ya que si lo anetrior se logra, el objeto aparecerá allí.\nLa estructura general para importar datos es la siguiente:\nread_*(\"ruta_hacia_archivo/nombre_archivo.*\")\n\nelsoc_2021 <- read_sav(\"ELSOC W05 v1.0 SPSS.sav\")  # No funciona\n\nelsoc_2021 <- read_sav(\"input/data/ELSOC W05 v1.0 SPSS.sav\") # No funciona\n\nelsoc_2021 <- read_sav(\"input/data/ELSOC_W05_v1.0_SPSS.sav\")\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos.\n\n\n\n2.1.1 Importar datos en otros formatos\n¡Bien hecho! Ahora bien, no siempre nuestros datos vendrán en un único formato. Para ello, R cuenta con otras formas de leer distintos tipos de formatos. Puedes ver las principales en el siguiente enlace."
  },
  {
    "objectID": "content/03-content.html#explorar-datos",
    "href": "content/03-content.html#explorar-datos",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "3 Explorar datos",
    "text": "3 Explorar datos"
  },
  {
    "objectID": "content/03-content.html#limpiar-datos",
    "href": "content/03-content.html#limpiar-datos",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "4 Limpiar datos",
    "text": "4 Limpiar datos\n\n4.1 Identificar\n\n\n4.2 Seleccionar\n\n\n4.3 Filtrar\n\n\n4.4 Recodificar\n\n\n4.5 Tratamiento casos pérdidos"
  },
  {
    "objectID": "content/03-content.html#transformar-variables",
    "href": "content/03-content.html#transformar-variables",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "5 Transformar variables",
    "text": "5 Transformar variables"
  },
  {
    "objectID": "content/03-content.html#guardar-y-exportar-datos-procesados",
    "href": "content/03-content.html#guardar-y-exportar-datos-procesados",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "6 Guardar y exportar datos procesados",
    "text": "6 Guardar y exportar datos procesados"
  },
  {
    "objectID": "content/03-content.html#resumen",
    "href": "content/03-content.html#resumen",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "Resumen",
    "text": "Resumen"
  },
  {
    "objectID": "content/03-content.html#video-de-clase",
    "href": "content/03-content.html#video-de-clase",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "Video de clase",
    "text": "Video de clase"
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Preguntas",
    "section": "",
    "text": "Para ver en pantalla completa presionar F (con cursor sobre presentación)"
  },
  {
    "objectID": "content/04-content.html#video-de-clase",
    "href": "content/04-content.html#video-de-clase",
    "title": "Preguntas",
    "section": "Video de clase",
    "text": "Video de clase"
  },
  {
    "objectID": "content/04-content.html#lecturas",
    "href": "content/04-content.html#lecturas",
    "title": "Preguntas",
    "section": "Lecturas",
    "text": "Lecturas\n\nCzaja & Blair (2005) Cap. 5 Questionnaire Design, Writing the questions"
  },
  {
    "objectID": "content/04-content.html#actividad-comenzar-a-preparar-trabajo-1",
    "href": "content/04-content.html#actividad-comenzar-a-preparar-trabajo-1",
    "title": "Preguntas",
    "section": "Actividad: Comenzar a preparar trabajo 1:",
    "text": "Actividad: Comenzar a preparar trabajo 1:\n\ngrupos de 3 integrantes\nseleccionar tema de interés general (ej: migración, género, clase social, pueblos originarios, uso del tiempo, bienestar, etc.)\ndefinir hipótesis y conceptos más específicos\ndefinir población objetivo\noperacionalizar\nbúsqueda de preguntas en bases de datos y literatura especializada\nadaptar / diseñar preguntas de distintos ámbitos y con distintas escalas de respuestas\nutilizar calificativos"
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "Cuestionario: formr",
    "section": "",
    "text": "Los contenidos principales de esta clase están relacionados con el tutorial de formr (sección recursos de este sitio)"
  },
  {
    "objectID": "content/05-content.html#documento-de-presentación",
    "href": "content/05-content.html#documento-de-presentación",
    "title": "Cuestionario: formr",
    "section": "Documento de presentación",
    "text": "Documento de presentación\n\n\n\nPara ver en pantalla completa presionar F (con cursor sobre presentación)"
  },
  {
    "objectID": "content/05-content.html#presentación-encuesta-microemprendimiento",
    "href": "content/05-content.html#presentación-encuesta-microemprendimiento",
    "title": "Cuestionario: formr",
    "section": "Presentación Encuesta Microemprendimiento",
    "text": "Presentación Encuesta Microemprendimiento\nDisponible en la sección de recursos, link aquí"
  },
  {
    "objectID": "content/05-content.html#lecturas",
    "href": "content/05-content.html#lecturas",
    "title": "Cuestionario: formr",
    "section": "Lecturas",
    "text": "Lecturas\n\nCzaja & Blair (2005) Cap. 5 Questionnaire Design, Organizing the questions"
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Flujo de trabajo reproducible y colaborativo",
    "section": "",
    "text": "Para ver en pantalla completa presionar F (con cursor sobre presentación)"
  },
  {
    "objectID": "content/08-content.html#video-de-la-clase",
    "href": "content/08-content.html#video-de-la-clase",
    "title": "Flujo de trabajo reproducible y colaborativo",
    "section": "Video de la clase",
    "text": "Video de la clase"
  },
  {
    "objectID": "content/08-content.html#lecturasmaterial",
    "href": "content/08-content.html#lecturasmaterial",
    "title": "Flujo de trabajo reproducible y colaborativo",
    "section": "Lecturas/material",
    "text": "Lecturas/material\n\nProtocolo reproducible IPO"
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Documentos dinámicos y (R)Markdown",
    "section": "",
    "text": "Para ver en pantalla completa presionar F (con cursor sobre presentación)"
  },
  {
    "objectID": "content/09-content.html#video-de-la-clase",
    "href": "content/09-content.html#video-de-la-clase",
    "title": "Documentos dinámicos y (R)Markdown",
    "section": "Video de la clase",
    "text": "Video de la clase"
  },
  {
    "objectID": "content/09-content.html#lecturasmaterial",
    "href": "content/09-content.html#lecturasmaterial",
    "title": "Documentos dinámicos y (R)Markdown",
    "section": "Lecturas/material",
    "text": "Lecturas/material\n\nM Editor.md - editor markdown online\nTutorial Markdown online\nThe Plain Person’s Guide to Plain Text Social Science\nIntroducción a RMarkdown\nRmarkdown / Rstudio\nRmarkdown en R4DS"
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Baterías e índices",
    "section": "",
    "text": "Para ver en pantalla completa presionar F (con cursor sobre presentación)"
  },
  {
    "objectID": "content/10-content.html#video-de-la-clase",
    "href": "content/10-content.html#video-de-la-clase",
    "title": "Baterías e índices",
    "section": "Video de la clase",
    "text": "Video de la clase\nParte1\n\n\n\n\n\nParte 2"
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "Análisis factorial",
    "section": "",
    "text": "Para ver en pantalla completa presionar F (con cursor sobre presentación)"
  },
  {
    "objectID": "content/11-content.html#video-de-la-clase",
    "href": "content/11-content.html#video-de-la-clase",
    "title": "Análisis factorial",
    "section": "Video de la clase",
    "text": "Video de la clase"
  },
  {
    "objectID": "content/11-content.html#recursos",
    "href": "content/11-content.html#recursos",
    "title": "Análisis factorial",
    "section": "Recursos",
    "text": "Recursos\n\nBrown (2015)The Common Factor Model and Exploratory Factor Analysis"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Laboratorio de Análisis de Datos",
    "section": "",
    "text": "En esta sección se encuentran las guías prácticas a desarrollar durante las sesiones del Laboratorio de Análisis de Datos.\nTodo el material es accesible desde el menú de la izquierda <–"
  },
  {
    "objectID": "content/index.html#instrucciones-generales-para-las-prácticas",
    "href": "content/index.html#instrucciones-generales-para-las-prácticas",
    "title": "Laboratorio de Análisis de Datos",
    "section": "Instrucciones generales para las prácticas",
    "text": "Instrucciones generales para las prácticas\n\nLas instancia prácticas consisten en el desarrollo de una guía práctica cada 2 semanas donde se aplican y profundizan los contenidos de las clases mediante las herramientas del lenguaje R. La organización de estas prácticas se puede revisar en la planificación del curso.\nEstas sesiones acompañarán el desarrollo de las guías prácticas disponibles en este sitio.\nEn las prácticas vamos a trabajar con el software R, Versión 4.2.2\nPara poder tener una asesoría y monitoreo más cercano en el desarrollo de las guías, los estudiantes han sido divididos en grupos asignados a un/a ayudante (ver en UCursos).\nEl trabajo con estas guías se organiza en los siguientes momentos:\n\nlas sesiones de laboratorios serán en modalidad online, en donde el equipo docente guiará el desarrollo del práctico\nel equipo docente mostrará el código para cada sesión, el cual contendrá los mismos contenidos de las guías alojadas en este sitio\nen paralelo, cada estudiante realiza esta guía de manera autónoma durante la sesión de laboratorio en su propio computador, apoyándose en el código que mostrarán los apoyos docentes\nen caso de dudas, las realizan en los foros disponibles o se contactan directamente con su ayudante"
  },
  {
    "objectID": "content/index.html#trabajo-con-software-r",
    "href": "content/index.html#trabajo-con-software-r",
    "title": "Laboratorio de Análisis de Datos",
    "section": "Trabajo con software R",
    "text": "Trabajo con software R\nPara los análisis estadísticos de este curso usamos el programa R, en parte porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\ntrabajar con la misma y última versión de R, que es la 4.2\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\n\nInstalación de R & RStudio\nPara esta versión del curso vamos a trabajar con el programa R Version 4.2 (se sugiere la última versión 4.2.2) y con RStudio, que ofrece un entorno más amigable para trabajar con R.\nPara instalar R: ir a https://cran.r-project.org/index.html y bajar/instalar la versión correspondiente a la plataforma utilizada (Windows, Mac o Linux)\nPara instalar RStudio: ir a https://posit.co/downloads/ y bajar/instalar RStudio desktop, Open Source License (libre).\nSi por alguna razón se prefiere trabajar sin descargar, también se puede utilizar RCloud, abajo un tutorial de una versión anterior del curso de estadística multivarada\n\n\n\n\n\n\n\nSobre el trabajo en hojas de código en RStudio\n\nEl trabajo de análisis en RStudio se efectua en una hoja de código (o R script o sintaxis, o para los usuarios de Stata la do-file), que es donde se anotan los comandos y funciones. Para abrir una hoja, en RStudio ir a File > New File > R Script (o ctrl+shift+N),y aparecerá un panel con una pestaña “Untitled” (sin título). Esta es la hoja de código donde se anotan los comandos.\nLos contenidos de las hojas de código son básicamente 2:\n\ncomandos o funciones: se escriben en la hoja, y para ejecutarlos se debe posicionar el cursor en la línea respectiva y ctrl+enter, el resultado aparecerá en el panel de resultados o Consola.\ntexto: para escribir títulos, comentarios, y todo lo que permita entender qué se está haciendo, al principio de la línea respectiva escribir el signo #\n\nPara grabar nuestra hoja de código y así respaldar nuestros análisis, File > Save (o ctrl+s), y dar un nombre al archivo. Recordar: breve, sin espacios ni tildes ni eñes. Por defecto, la extensión de estos archivos es .R"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística Descriptiva",
    "section": "",
    "text": "Estadística Descriptiva\n        \n        \n            \n        \n        \n            SOC01014-1 • Primer Semestre 2023Departamento de Sociología FACSOUniversidad de Chile\n        \n    \n    \n        \n    \n\n\n\n\n\nProfesor\n\n   Rodrigo Asún\n   Departamento de Sociología FACSO\n   rasun@uchile.cl\n\n\n\nEquipo docente\n\n   Daniela Olivares\n   dsolivares@uc.cl\n   Andreas Laffert\n   andreas.laffert@ug.uchile.cl\n\n\n\nInformación del curso\n\n   Jueves\n   Marzo–Julio, 2023\n   8:30 AM - 11:45 AM\n   Aulario A - sala 7 y 8\n\n\n\nContacto\nA través de correo o U-Cursos"
  },
  {
    "objectID": "resource/01-resource.html",
    "href": "resource/01-resource.html",
    "title": "Bases de datos",
    "section": "",
    "text": "Encuestas CEP\nELSOC\nCASEN\nENETS\nENE\nESI\nENCLA\nENUT\nEstudios PNUD\nENDIDE\nEANNA"
  },
  {
    "objectID": "resource/01-resource.html#internacionales",
    "href": "resource/01-resource.html#internacionales",
    "title": "Bases de datos",
    "section": "Internacionales",
    "text": "Internacionales\n\nILO\nWID\nSWIID\nICTWSS\nOECD\nBanco Mundial"
  },
  {
    "objectID": "resource/01-resource.html#comparativas",
    "href": "resource/01-resource.html#comparativas",
    "title": "Bases de datos",
    "section": "Comparativas",
    "text": "Comparativas\n\nWorld Values Survey\nISSP\nESS\nLAPOP\nLatinobarómetro"
  },
  {
    "objectID": "resource/02-resource.html",
    "href": "resource/02-resource.html",
    "title": "Uso de R",
    "section": "",
    "text": "Recursos web para aprender R\n\nR para Ciencia de Datos\nHands-On Programming with R\nManual de R\nMás libros de R\nAnalizaR Datos Políticos\nR Cheatsheets\nGuías rápidas en R\nRStudio para Estadística Descriptiva en Ciencias Sociales\n\n\n\nVisualización de datos en R\n\nR Graph Gallery\nData to Viz\nData Visualization Course\n\n\n\nSitios de consulta y comunidad de R\n\nStack Overflow\nGeeks for geeks\nChatGPT\nRstudio Community"
  },
  {
    "objectID": "resource/05-resource.html",
    "href": "resource/05-resource.html",
    "title": "Análisis Factorial Exploratorio",
    "section": "",
    "text": "pacman::p_load(stargazer, # Reporte\nsjPlot, sjmisc, # reporte y gráficos\nsjlabelled,\ncorrplot, # grafico correlaciones\nxtable, # Reporte\nHmisc, # varias funciones\npsych, # fa y principal factors\npsy, # scree plot function\nnFactors, # parallel\nGPArotation) # rotación\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\nalso installing the dependency 'htmlTable'\n\n\n\nHmisc installed\n\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\n\npsy installed\n\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\n\nnFactors installed\n\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\n\nGPArotation installed\n\n\n\n\n\nLectura de datos\n\ndata <- read.csv(\"input/data/efa_asignaturas.csv\")\n\n\n\n\n\nMuestra de 300 alumnos a los que se le pregunta por su asignatura favorita en una escala de 1 (no me agrada) a 5 (me agrada)\n\n\n\n\n\nsummary(data)\n\n      BIO             GEO            CHEM            ALG            CALC      \n Min.   :1.000   Min.   :1.00   Min.   :1.000   Min.   :1.00   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:1.00   1st Qu.:1.000   1st Qu.:2.00   1st Qu.:2.000  \n Median :2.000   Median :2.00   Median :2.000   Median :3.00   Median :3.000  \n Mean   :2.353   Mean   :2.17   Mean   :2.237   Mean   :3.05   Mean   :3.063  \n 3rd Qu.:3.000   3rd Qu.:3.00   3rd Qu.:3.000   3rd Qu.:4.00   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.00   Max.   :5.000   Max.   :5.00   Max.   :5.000  \n      STAT      \n Min.   :1.000  \n 1st Qu.:2.000  \n Median :3.000  \n Mean   :2.937  \n 3rd Qu.:4.000  \n Max.   :5.000  \n\nnames(data)\n\n[1] \"BIO\"  \"GEO\"  \"CHEM\" \"ALG\"  \"CALC\" \"STAT\"\n\ndim(data)  # filas columnas\n\n[1] 300   6\n\nnrow(na.omit(data)) # número de casos con datos completos\n\n[1] 300"
  },
  {
    "objectID": "resource/05-resource.html#gráfico-barras-apiladas",
    "href": "resource/05-resource.html#gráfico-barras-apiladas",
    "title": "Análisis Factorial Exploratorio",
    "section": "Gráfico barras apiladas",
    "text": "Gráfico barras apiladas\n\n#sjplot(data$BIO, \"frq\") # no muy buena descripción ...\n\nnames(data)\n\n[1] \"BIO\"  \"GEO\"  \"CHEM\" \"ALG\"  \"CALC\" \"STAT\"\n\nplot_stackfrq(data)\n\n\n\n\nGráfico final\n\n#label values\n\ndata <- data %>%  set_labels (., labels=c(\"No le agrada\"=1,\n  \"Le agrada\"=5))\n\nplot_stackfrq(data, sort.frq = \"last.desc\", geom.colors = \"OrRd\") #+ theme(legend.position=\"bottom\")"
  },
  {
    "objectID": "resource/05-resource.html#analisis-de-matriz-de-correlaciones",
    "href": "resource/05-resource.html#analisis-de-matriz-de-correlaciones",
    "title": "Análisis Factorial Exploratorio",
    "section": "Analisis de matriz de correlaciones",
    "text": "Analisis de matriz de correlaciones\nMatriz\n\ncorMat  <- cor(data)  # estimar matriz pearson\noptions(digits=2)\ncorMat # muestra matriz\n\n      BIO  GEO  CHEM   ALG CALC STAT\nBIO  1.00 0.68 0.747 0.115 0.21 0.20\nGEO  0.68 1.00 0.681 0.135 0.20 0.23\nCHEM 0.75 0.68 1.000 0.084 0.14 0.17\nALG  0.12 0.14 0.084 1.000 0.77 0.41\nCALC 0.21 0.20 0.136 0.771 1.00 0.51\nSTAT 0.20 0.23 0.166 0.409 0.51 1.00\n\n\nReporte tabla\n\ntab_corr(data, triangle = \"lower\")\n\n\n\n\n \nBIO\nGEO\nCHEM\nALG\nCALC\nSTAT\n\n\nBIO\n \n \n \n \n \n \n\n\nGEO\n0.682***\n \n \n \n \n \n\n\nCHEM\n0.747***\n0.681***\n \n \n \n \n\n\nALG\n0.115*\n0.135*\n0.084\n \n \n \n\n\nCALC\n0.213***\n0.205***\n0.136*\n0.771***\n \n \n\n\nSTAT\n0.203***\n0.232***\n0.166**\n0.409***\n0.507***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n \n\n\n\nReporte gráfico con corrplot\n\nM=cor(data) # matriz simple de correlaciones de los datos\ncorrplot(M, type=\"lower\") # lower x bajo diagonal\n\n\n\n\nOtra opción\n\ncorrplot(M, type=\"lower\",\n      order=\"AOE\", cl.pos=\"b\", tl.pos=\"d\") #agrega nombres en diag."
  },
  {
    "objectID": "resource/05-resource.html#seleccion-de-numero-de-factores",
    "href": "resource/05-resource.html#seleccion-de-numero-de-factores",
    "title": "Análisis Factorial Exploratorio",
    "section": "Seleccion de numero de factores",
    "text": "Seleccion de numero de factores\nGraficos\n\nscree.plot(data)\n\n\n\n\n\nfa.parallel(corMat, n.obs=300)\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  2 \n\n\n\nlibrary(nFactors)\nev <- eigen(corMat) # get eigenvalues\nap <- parallel(subject=300,var=6,\n  rep=100,cent=.05)\nnS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)\nplotnScree(nS)\n\n\n\n\nFactor de aceleración: solución numérica que muestra el punto que presenta el mayor cambio de pendiente\nOptimal coordinates: muestra el primer eigenvalue que puede ser mejor “extrapolado” desde el eigenvalue previo (“optimal coordinates are the extrapolated coordinates of the previous eigenvalue that allow the observed eigenvalue to go beyond this extrapolation” (http://www.inside-r.org/packages/cran/nFactors/docs/nScree)"
  },
  {
    "objectID": "resource/05-resource.html#extracción",
    "href": "resource/05-resource.html#extracción",
    "title": "Análisis Factorial Exploratorio",
    "section": "Extracción",
    "text": "Extracción\nEjes principales\n\nfac_pa <- fa(r = data, nfactors = 2, fm= \"pa\")\n#summary(fac_pa)\nfac_pa\n\nFactor Analysis using method =  pa\nCall: fa(r = data, nfactors = 2, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       PA1   PA2   h2    u2 com\nBIO   0.86  0.02 0.75 0.255 1.0\nGEO   0.78  0.05 0.63 0.369 1.0\nCHEM  0.87 -0.05 0.75 0.253 1.0\nALG  -0.04  0.81 0.65 0.354 1.0\nCALC  0.01  0.96 0.92 0.081 1.0\nSTAT  0.13  0.50 0.29 0.709 1.1\n\n                       PA1  PA2\nSS loadings           2.14 1.84\nProportion Var        0.36 0.31\nCumulative Var        0.36 0.66\nProportion Explained  0.54 0.46\nCumulative Proportion 0.54 1.00\n\n With factor correlations of \n     PA1  PA2\nPA1 1.00 0.21\nPA2 0.21 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.9 with Chi Square =  849\ndf of  the model are 4  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  300 with the empirical chi square  0.78  with prob <  0.94 \nThe total n.obs was  300  with Likelihood Chi Square =  3.3  with prob <  0.51 \n\nTucker Lewis Index of factoring reliability =  1\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.08\nBIC =  -20\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2\nCorrelation of (regression) scores with factors   0.94 0.96\nMultiple R square of scores with factors          0.88 0.93\nMinimum correlation of possible factor scores     0.77 0.86\n\n\nMaximum likelihood\n\nfac_ml <- fa(r = data, nfactors = 2, fm= \"ml\")\nsummary(fac_ml)\n\nPlot de cargas factoriales ml\n\nfactor.plot(fac_ml, labels=rownames(fac_ml$loadings))\n\n\n\n\nObtención de Puntajes factoriales\nLos puntajes factoriales son vectores/variables que representan al factor latente como una variable observada y que por lo tanto suma una columna a la base de datos por cada factor extraído. Como la variable latente no tiene métrica, se le otorga una con media 0 y varianza 1. Los puntajes son una especie de índice pero donde la constribución de cada indicador al índice se encuentra ponderada por su carga factorial (su contribución a la variable latente común o factor).\n\nfac_ml <- fa(r = data, nfactors = 2, fm= \"ml\", scores=\"regression\")\ndata2=data\ndata3 <- cbind(data2, fac_ml$scores)\nhead(data3)\n\n  BIO GEO CHEM ALG CALC STAT    ML2   ML1\n1   1   1    1   1    1    1 -1.110 -1.84\n2   4   4    3   4    4    4  1.153  0.85\n3   2   1    3   4    1    1 -0.188 -1.61\n4   2   3    2   4    4    3 -0.013  0.82\n5   3   1    2   2    3    4 -0.070 -0.11\n6   1   1    1   4    4    4 -1.022  0.84"
  },
  {
    "objectID": "resource/05-resource.html#rotación",
    "href": "resource/05-resource.html#rotación",
    "title": "Análisis Factorial Exploratorio",
    "section": "Rotación",
    "text": "Rotación\nVarimax (ortogonal)\n\nfac_ml_var <- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n      ML2  ML1   h2    u2 com\nBIO  0.85 0.13 0.75 0.252 1.0\nGEO  0.78 0.13 0.63 0.375 1.1\nCHEM 0.86 0.06 0.75 0.249 1.0\nALG  0.03 0.79 0.63 0.374 1.0\nCALC 0.10 0.97 0.95 0.048 1.0\nSTAT 0.17 0.51 0.29 0.715 1.2\n\n                       ML2  ML1\nSS loadings           2.12 1.86\nProportion Var        0.35 0.31\nCumulative Var        0.35 0.66\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.9 with Chi Square =  849\ndf of  the model are 4  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  300 with the empirical chi square  0.97  with prob <  0.91 \nThe total n.obs was  300  with Likelihood Chi Square =  2.9  with prob <  0.57 \n\nTucker Lewis Index of factoring reliability =  1\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.076\nBIC =  -20\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML1\nCorrelation of (regression) scores with factors   0.94 0.98\nMultiple R square of scores with factors          0.88 0.95\nMinimum correlation of possible factor scores     0.76 0.91\n\n\nPromax (oblicua)\n\nfac_ml_pro <- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       ML2   ML1   h2    u2 com\nBIO   0.86  0.02 0.75 0.252 1.0\nGEO   0.78  0.03 0.63 0.375 1.0\nCHEM  0.88 -0.06 0.75 0.249 1.0\nALG  -0.09  0.81 0.63 0.374 1.0\nCALC -0.05  0.99 0.95 0.048 1.0\nSTAT  0.10  0.50 0.29 0.715 1.1\n\n                       ML2  ML1\nSS loadings           2.12 1.86\nProportion Var        0.35 0.31\nCumulative Var        0.35 0.66\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\n With factor correlations of \n     ML2  ML1\nML2 1.00 0.28\nML1 0.28 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.9 with Chi Square =  849\ndf of  the model are 4  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  300 with the empirical chi square  0.97  with prob <  0.91 \nThe total n.obs was  300  with Likelihood Chi Square =  2.9  with prob <  0.57 \n\nTucker Lewis Index of factoring reliability =  1\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.076\nBIC =  -20\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML1\nCorrelation of (regression) scores with factors   0.94 0.98\nMultiple R square of scores with factors          0.89 0.96\nMinimum correlation of possible factor scores     0.77 0.91"
  },
  {
    "objectID": "resource/05-resource.html#reporte-tabla-análisis-factorial",
    "href": "resource/05-resource.html#reporte-tabla-análisis-factorial",
    "title": "Análisis Factorial Exploratorio",
    "section": "Reporte: Tabla análisis factorial",
    "text": "Reporte: Tabla análisis factorial\nA html via sjPlot\n\ntab_fa(data, rotation = \"varimax\",show.comm = TRUE, title = \"Análisis factorial asignaturas\")\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n\n\n\nAnálisis factorial asignaturas\n\n \nFactor 1\nFactor 2\nCommunality\n\n\nBIO\n0.85\n0.13\n0.75\n\n\nGEO\n0.78\n0.13\n0.63\n\n\nCHEM\n0.86\n0.06\n0.75\n\n\nALG\n0.03\n0.79\n0.63\n\n\nCALC\n0.10\n0.97\n0.95\n\n\nSTAT\n0.17\n0.51\n0.29\n\n\nTotal Communalities\n\n3.99\n\n\nCronbach's α\n0.88\n0.79"
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos adicionales",
    "section": "",
    "text": "En esta sección se presentan una serie de recursos como ejemplos de bases de datos, tutoriales, guías y sitios de consulta sobre el uso de R."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los dos componentes centrales del curso son las clases lectivas y las sesiones de Laboratorio de Análisis de Datos. Las clases se realizarán los días Jueves 08:30 a 11:45  en sala sala 7 y 8 del Aulario A\n\nClases ( ): Lecturas y documentos de presentación.\nPrácticas (): Actividades prácticas en Laboratorio de Análisis de Datos a desarrollar durante el semestre.\nLecturas (): Llegar a la clase con los textos leídos."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Rodrigo Asún\n   Departamento de Sociología FACSO\n   rasun@uchile.cl\n\n\n\n\n\n   Jueves\n   Marzo–Julio, 2023\n   8:30 AM - 11:45 AM\n   Aulario A - sala 7 y 8"
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico diferenciando entre tipos de variables, niveles de medición y formas de distribución. Se espera que los estudiantes sean capaces de diseñar y depurar bases de datos; identificar y definir diferentes tipos de muestreo; aplicar de manera pertinente, estadísticos descriptivos uni y bivariados, utilizar diferentes softwares de análisis estadístico; a partir de los cuáles puedan desarrollar análisis de problemas sociales; contrastar hipótesis de investigación; y elaborar conclusiones integrando fundamentos teóricos con herramientas de análisis estadístico de resultados. Complementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos."
  },
  {
    "objectID": "syllabus.html#competencias",
    "href": "syllabus.html#competencias",
    "title": "Programa",
    "section": "Competencias",
    "text": "Competencias\n\nDelimitar, conceptualizar y analizar diversos objetos de investigación social, con especial énfasis en aquellos relacionados con los procesos de transformación del país y Latinoamérica\nManejar diversas estrategias metodológicas de las ciencias sociales\nManejar un conjunto de herramientas para el procesamiento y análisis de información\nTransmitir los conocimientos derivados de la práctica investigativa, así como aquellos adquiridos durante el proceso formativo.\n\n\nSubcompetencias\n\nContribuir a generar conocimiento sociológico en el marco de estudios y/o procesos de investigación donde se articulen creativamente las dimensiones teórica, metodológica y práctica.\nComunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos."
  },
  {
    "objectID": "syllabus.html#resultados-de-aprendizaje",
    "href": "syllabus.html#resultados-de-aprendizaje",
    "title": "Programa",
    "section": "Resultados de Aprendizaje",
    "text": "Resultados de Aprendizaje\nAl finalizar el curso, los estudiantes serán capaces de:\n\nComprender la relevancia del análisis estadístico como herramienta para la investigación sociológica y la comprensión de lo social.\nConocer y manejar a nivel inicial las herramientas estadísticas e informáticas necesarias para realizar análisis y descripciones univariadas de datos sociales y sociológicos.\nResolver problemas de investigación sociológica simples a partir del uso de técnicas de cálculo, análisis y visualización estadística."
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / contenidos",
    "text": "Saberes / contenidos\n\nUNIDAD I. Sociología y estadística: algunas vinculaciones y conceptos fundamentales\n1.1.- ¿Por qué debe aprender estadística un estudiante o una estudiante de sociología?\n● La construcción de conocimiento sociológico y la estadística.\n● La estrategia de investigación cuantitativa: estrategia epistemológica, limitaciones y potencialidades.\n1.2.- La medición en ciencias sociales:\n● Medir en ciencias sociales: del constructo teórico al dato estadístico.\n● Tipos de variables y niveles de medición.\n● La noción de población, muestra, estadístico, parámetro y estimación.\n1.3.- Datos y bases de datos:\n● Las fuentes de información: tratamiento, producción y análisis de datos primarios y secundarios.\n● Manejo y depuración de datos y bases de datos.\n● Aspectos éticos\n\n\nUNIDAD II. La descripción de los datos: Medidas de tendencia central, dispersión y posición.\n2.1.- Medidas de tendencia central\n● Supuestos sociológicos tras las medidas de tendencia central. Ejemplos de investigaciones sociológicas relevantes.\n● La media, la media recortada, la mediana y la moda. Potencialidades y limitaciones.\n2.2.- Medidas de dispersión\n● Supuestos sociológicos tras las medidas de dispersión. Ejemplos de investigaciones sociológicas relevantes.\n● Rango, varianza y desviación típica. Coeficiente de variación. Representaciones gráficas.\n2.3.- Medidas de Posición\n● Distribuciones de frecuencias absoluta, relativa y acumulada.\n● Medidas de posición no central: los cuantiles.\n● Representaciones gráficas.\n\n\nUNIDAD III. La forma de una distribución\n● Noción de función, distribución empírica, teórica y de muestreo. Distribución discreta y distribución continua.\n● Características de la forma de una distribución: Asimetría y Curtosis.\n● Introducción a la distribución normal. Principales características de la distribución. Uso de la distribución normal. Estandarización y puntaje Z.\n● Introducción a otras distribuciones.\n\n\nUNIDAD IV. Inferencia estadística univariada: de la estimación puntual al parámetro\n● Tipos de hipótesis y prueba estadística.\n● Confianza, potencia y error.\n● Estimadores puntuales para medias y proporciones.\n● Conceptos de error típico, nivel de confianza y error de estimación.\n● La construcción de intervalos de confianza para medias y proporciones.\n● Ponderadores y sesgos en estimación de parámetros poblacionales."
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nLa asignatura se desarrollará a través de:\n\nClases lectivas o exposiciones a cargo del profesor, en las que se presentarán las principales temáticas de la asignatura, y en las que los y las estudiantes tendrán la posibilidad de resolver dudas relacionadas con los aspectos teóricos/conceptuales.\nUn Laboratorio de Análisis de Datos (LAB) a cargo del profesor y Equipo Docente. Se realizarán ejercicios prácticos de procesamiento, análisis e interpretación de resultados mediante diversos softwares de análisis estadístico (Excel, Spss y R, fundamentalmente). En ellos los y las estudiantes aprenderán a interpretar sociológicamente datos provenientes de múltiples fuentes, visualizar datos en forma gráfica, así como elaborar reportes de resultados.\nFinalmente, se realizarán sesiones de ayudantía específicas para reforzamiento de contenidos y del trabajo del Laboratorio de Análisis de Datos.\nSe reforzarán los contenidos con la entrega de material audiovisual y tutoriales"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nDurante el transcurso de la asignatura (y en el marco del Laboratorio de Análisis de Datos) se realizará un Trabajo de Taller Colectivo (con 2 entregas a lo largo del semestre) y 3 Tareas Individuales.\n● Los grupos de Taller Colectivo (de cuatro estudiantes) tendrán asignado un/a ayudante que acompañará el proceso durante todo el semestre. Las dos entregas del taller valdrán un 30% de la nota final (60% por los talleres colectivos).\n● Se realizarán 3 Tareas Individuales. Cada tarea individual valdrá un 13,3% de la nota final (40% en total por las tareas individuales).\nPara cautelar que se logren los resultados de aprendizaje, en los Talleres Colectivos los estudiantes deberán incluir reflexiones respecto de la utilidad de la estadística para la comprensión de los temas sociológicamente relevantes que estarán analizando. Por otro parte, tanto en los Talleres Colectivos como en las Tareas Individuales los estudiantes deberán demostrar su manejo de las herramientas estadísticas e informáticas enseñadas durante el curso y producir una conclusión sustantiva sobre los datos que estén procesando, con lo que se evaluarán los resultados de aprendizaje 2 y 3."
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\nASISTENCIA: Se establece una asistencia de al menos el 50% de las clases. La asistencia habilita al estudiante a presentarse al examen de primera oportunidad.\nNOTA DE APROBACIÓN MÍNIMA (Escala de 1.0 a 7.0): 4.0\nNOTA DE EXIMICIÓN MÍNIMA: 5.0\nREQUISITOS PARA PRESENTACIÓN A EXAMEN:\nPara presentarse al examen de primera oportunidad debe cumplir con: - Nota de presentación igual o superior a 3.5 - Al menos un 50% de asistencia. El estudiante se presentará al examen de segunda oportunidad en los siguientes casos: - Nota final inferior a 3.5 - Haber reprobado el curso luego de rendir el examen de primera oportunidad - No cumplimiento del mínimo de asistencia establecido en el programa (50%)."
  },
  {
    "objectID": "syllabus.html#palabras-clave",
    "href": "syllabus.html#palabras-clave",
    "title": "Programa",
    "section": "Palabras Clave",
    "text": "Palabras Clave\n\nEstadística Descriptiva, Estadística Univariada, Medidas de tendencia central, medidas de dispersión, Distribución Normal."
  },
  {
    "objectID": "syllabus.html#bibliografía-obligatoria",
    "href": "syllabus.html#bibliografía-obligatoria",
    "title": "Programa",
    "section": "Bibliografía Obligatoria",
    "text": "Bibliografía Obligatoria\n● Blalock, H. (1986). Estadística Social. México D.F.: Fondo de Cultura Económica.\n● Ferrando, M. (1999): Socioestadística: Introducción a la Estadística en Sociología. Alianza Editorial.\n● Pardo Merino, A., & San Martín Castellanos, R. (2010). Análisis de datos en ciencias sociales y de la salud II. Síntesis, Madrid.\n● Cea, D’Ancona, M. (2001). Metodología Cuantitativa. Estrategias y técnicas de investigación social. Síntesis.\n● Asún, R. (2006). Medir la Realidad Social: el sentido de la investigación cuantitativa. En: M. Canales (Ed.). Metodologías de Investigación Social (pp. 29-60). Santiago de Chile: LOM. 21.\n\nBibliografía Complementaria\n● Field, A. (2009). Discovering Statistics Using IBM SPSS. California: SAGE Publications. Disponible online en: http://www.soc.univ.kiev.ua/sites/default/files/library/elopen/andyfield-discovering-statistics-using-spss-third-edition-20091.pdf\n● Field, A., Miles, J. y Field, Z. (2012) Discovering Statistics Using R. California: SAGE Publications.\n● Boccardo, G. & Ruiz, F. (2019). RStudio para Estadística Descriptiva en Ciencias Sociales. Segunda edición. En línea en: https://bookdown.org/. Departamento de Sociología, Facultad de Ciencias Sociales, Universidad de Chile.\n● Ritchey, F. J. (2008). Estadística para las ciencias sociales. McGraw-Hill.\n● Stallman, R. (2004). Software libre para una sociedad libre. En línea en: https://www.traficantes.net/. Traficantes de Sueños.\n● Wrigth Mills, C. (1975). Empirismo abstracto. En: La imaginación sociológica. México: Fondo de Cultura Económica.\n● de Micheaux, P. L., Drouilhet, R., & Liquet, B. (2013). The R software.Fundamentals of Programming and Statistical Analysis. Springer.\n● Elousa, P. (2009). ¿Existe vida más allá del SPSS? Descubre R. En Revista Psicothema, vol.21, n° 4, pp. 652-655. Disponible online en: www.ehu.eus/gip/publicaciones/articulos/2009/2.pdf\n● González, F. (2019). Big data, algoritmos y política: las ciencias sociales en la era de las redes digitales. Revista Cinta moebio 65: pp. 267-280.\n● Grolemund & Wickham (2016). R for Data Science. Disponible en línea en: https://r4ds.had.co.nz/. O’Reilly Media.\n● Paradis, E. (2003). R para Principiantes. Francia: Institut des Sciences de l’Évolution. Disponible oline en: https://cran.r-project.org/doc/contrib/rdebuts_es.pdf\n● Urdines, F. & Cruz, A. (2019). Analiza R Datos Políticos. Instituto de Ciencia Política de la Universidad Católica de Chile. Disponible en línea: https://arcruz0.github.io/\n● Wickham, H. (2015). ggplot2: Elegant Graphics for Data Analysis. Disponible en línea en: https://ggplot2-book.org/. Springer."
  },
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "El curso tendrá dos instancias de evaluación:\n\nTaller Colectivo: Este taller grupal (60% de la nota final) tiene por objetivo aplicar los contenidos del curso a una tématica de interés específica en formato de artículo de investigación breve. Esto implica que los estudiantes deberán plantear un fenómeno social a investigar, el problema de investigación y su relevencia, precisar el argumento o hipótesis central, describir la metodología utilizada y analizar descriptivamente variables relativas a dicho fenónomeno. Consistirá en dos informes, uno de diseño de investigación (20%) y otro de análisis y conclusiones (40%). Los talleres son elaborados en grupos de máximo 4 integrantes.\nTareas Individuales: Las tareas individuales (40% de la nota final) tienen por objetivo aplicar los contenidos del Laboratorio de Análisis de Datos y también de las clases lectivas del curso a actividades prácticas. Esto implica que los estudiantes deberán demostrar el aprendizaje de herramientas básicas de procesamiento, limpieza y manipulación de datos, además de analizar descriptivamente y visualizar variables, todo ello siendo correctamente reportado. Consistirán en tres tareas individuales a lo largo del semestre, en donde cada una equivaldrá a un 13.3%."
  },
  {
    "objectID": "trabajos.html#taller-colectivo",
    "href": "trabajos.html#taller-colectivo",
    "title": "Trabajos",
    "section": "Taller Colectivo",
    "text": "Taller Colectivo\n\nInforme 1\n\n\nInforme 2"
  },
  {
    "objectID": "trabajos.html#tareas-individuales",
    "href": "trabajos.html#tareas-individuales",
    "title": "Trabajos",
    "section": "Tareas Individuales",
    "text": "Tareas Individuales\n\nTarea 1\n\n\nTarea 2\n\n\nTarea 3"
  },
  {
    "objectID": "resource/03-resource.html",
    "href": "resource/03-resource.html",
    "title": "Importar datos en R",
    "section": "",
    "text": "pacman::p_load(tidyverse,\n               sjmisc,\n               dplyr,\n               haven,\n               readxl)"
  }
]